{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "020856cb-4a8a-47f4-8724-6706a97e5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c140973-ffec-49eb-b6a8-4bdad13baa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/chehakarora/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure NLTK resources are available\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd431f7-1dea-42f0-9910-9316c7ea83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('trainSA.csv')\n",
    "data_test = pd.read_csv('testSA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28015516-3283-48fe-9839-943ce2dd1750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "                                                text      category\n",
      "0                     I am still waiting on my card?  card_arrival\n",
      "1  What can I do if my card still hasn't arrived ...  card_arrival\n",
      "2  I have been waiting over a week. Is the card s...  card_arrival\n",
      "3  Can I track my card while it is in the process...  card_arrival\n",
      "4  How do I know if I will get my card, or if it ...  card_arrival\n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset Overview:\")\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a79eae8f-e424-4638-8fbb-231bd48b8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data - standardize text data gets rid of extra space, ?, !\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "data_train['clean_text'] = data_train['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae93c8f0-9f15-4376-823a-a90806a21aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VADER sentiment analysis to get sentiment score \n",
    "\n",
    "# Sentiment Analysis - clean text is preprocessed text, VADER to analyze the sentiment. .compound will extract the overall sentiment score. \n",
    "sia = SentimentIntensityAnalyzer()\n",
    "data_train['sentiment_score'] = data_train['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad367983-e58e-45b4-81d2-982ea70991af",
   "metadata": {},
   "source": [
    "Multilabel Binarizer converts labels into a binary matrix, each unique category will get a new feature matrix. \n",
    "text is converted to numbers through TF-IDF vectorization based on importance of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb05d08c-dd83-494f-8afe-50e9292cc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert intents into multi-label format\n",
    "mlb = MultiLabelBinarizer()\n",
    "category_features_train = mlb.fit_transform(data_train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ae28a59-8030-4dc2-a4c1-5114f8716c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "text_features_train = tfidf.fit_transform(data_train['clean_text']).toarray()\n",
    "# Stack text and category features horizontally\n",
    "features_train = np.hstack((text_features_train, category_features_train)) #features contain both text based and category based numerical representations.\n",
    "print(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e4235-1f0e-42fa-aca7-2a98e51381dc",
   "metadata": {},
   "source": [
    "Isolation forest is an unsupervised anomaly detection algorithm, it separates the data by randomly partitioning the dataset. Assigns an anomaly score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13331bda-c703-4026-8b96-0158bdb0eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomalous Conversations in Training data:\n",
      "                                                   text  \\\n",
      "58    I know I'm getting a new card but would like k...   \n",
      "127   Am I able to track a card that has already bee...   \n",
      "137   I was issued a new card a week ago but still h...   \n",
      "143   I was supposed to receive my new card by now, ...   \n",
      "154   I was able to find my card. How to I go about ...   \n",
      "...                                                 ...   \n",
      "9407  I want to get some cash from the ATM using my ...   \n",
      "9419  I just took some cash out of a cash machine in...   \n",
      "9464  It seems I've suddenly been charged for my rec...   \n",
      "9525  Does it cost much or take long to get a new ca...   \n",
      "9565  If my card is about to expire how long would i...   \n",
      "\n",
      "                    category anomaly_flag  \n",
      "58              card_arrival    Anomalous  \n",
      "127             card_arrival    Anomalous  \n",
      "137             card_arrival    Anomalous  \n",
      "143             card_arrival    Anomalous  \n",
      "154             card_linking    Anomalous  \n",
      "...                      ...          ...  \n",
      "9407  cash_withdrawal_charge    Anomalous  \n",
      "9419  cash_withdrawal_charge    Anomalous  \n",
      "9464  cash_withdrawal_charge    Anomalous  \n",
      "9525    card_about_to_expire    Anomalous  \n",
      "9565    card_about_to_expire    Anomalous  \n",
      "\n",
      "[501 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "iso_forest.fit(features_train)\n",
    "\n",
    "# Fit the model and predict anomalies\n",
    "data_train['anomaly'] = iso_forest.predict(features_train)\n",
    "\n",
    "# Mark anomalies (-1 means anomaly, 1 means normal)\n",
    "data_train['anomaly_flag'] = data_train['anomaly'].apply(lambda x: 'Anomalous' if x == -1 else 'Normal')\n",
    "\n",
    "# Show flagged anomalies\n",
    "print(\"\\nAnomalous Conversations in Training data:\")\n",
    "print(data_train[data_train['anomaly_flag'] == 'Anomalous'][['text', 'category', 'anomaly_flag']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d32db28-8972-4925-abfa-6a3517b66b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['clean_text'] = data_test['text'].apply(preprocess_text)\n",
    "data_test['sentiment_score'] = data_test['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3de77f5-8520-4895-a0ad-f855abd4445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features_test = mlb.transform(data_test['category'])\n",
    "text_features_test = tfidf.transform(data_test['clean_text']).toarray()\n",
    "features_test = np.hstack((text_features_test, category_features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29a0c706-f5a8-458e-a659-0c7c5b03596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['anomaly'] = iso_forest.predict(features_test)\n",
    "data_test['anomaly_flag'] = data_test['anomaly'].apply(lambda x: 'Anomalous' if x == -1 else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d71825f-fa24-4965-891b-2e00da16b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomalous Conversations in Test Data:\n",
      "                                                   text  \\\n",
      "192   Can you help me with a weird charge?  It's a p...   \n",
      "198   I'm quite confused as to what is going on. The...   \n",
      "203   Hey I tried to get some money out earlier but ...   \n",
      "207   I got some cash of an ATM earlier but this sho...   \n",
      "210   Hi! I was wondering if you can help me. I used...   \n",
      "...                                                 ...   \n",
      "2745  I need to cancel my card that got stolen a lit...   \n",
      "2753  I didn't take out money from an ATM but my app...   \n",
      "2754  Someone has stolen my card. Even though I have...   \n",
      "2884  Why are fees charged on cash withdrawals? I we...   \n",
      "2972  I received my American Express card, but I am ...   \n",
      "\n",
      "                            category anomaly_flag  \n",
      "192        extra_charge_on_statement    Anomalous  \n",
      "198        extra_charge_on_statement    Anomalous  \n",
      "203          pending_cash_withdrawal    Anomalous  \n",
      "207          pending_cash_withdrawal    Anomalous  \n",
      "210          pending_cash_withdrawal    Anomalous  \n",
      "...                              ...          ...  \n",
      "2745  cash_withdrawal_not_recognised    Anomalous  \n",
      "2753  cash_withdrawal_not_recognised    Anomalous  \n",
      "2754  cash_withdrawal_not_recognised    Anomalous  \n",
      "2884          cash_withdrawal_charge    Anomalous  \n",
      "2972         apple_pay_or_google_pay    Anomalous  \n",
      "\n",
      "[104 rows x 3 columns]\n",
      "\n",
      "Anomaly detection on test data completed! Results saved to 'flagged_conversations_test.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnomalous Conversations in Test Data:\")\n",
    "print(data_test[data_test['anomaly_flag'] == 'Anomalous'][['text', 'category', 'anomaly_flag']])\n",
    "\n",
    "# Save the test results\n",
    "data_test.to_csv('flagged_conversations_test.csv', index=False)\n",
    "print(\"\\nAnomaly detection on test data completed! Results saved to 'flagged_conversations_test.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2023641-caa1-47f8-837a-bb84dc7a5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming you have the true labels and anomaly scores for the test data\n",
    "\n",
    "# If you are using the Isolation Forest model, you can get anomaly scores like this:\n",
    "# For anomaly detection, use `decision_function` or `score_samples` to get the anomaly score (lower score = more anomalous).\n",
    "anomaly_scores = iso_forest.decision_function(features_test)  # Get anomaly scores for the test data\n",
    "\n",
    "# For ROC, you need a score or probability, so use the decision function output.\n",
    "# Higher score means more \"normal\", lower score means more \"anomalous\"\n",
    "# The decision function output for Isolation Forest is typically negative for anomalies and positive for normal points.\n",
    "\n",
    "# Now, let's compute the ROC curve and AUC.\n",
    "fpr, tpr, thresholds = roc_curve(data_test['true_label'], anomaly_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC (Area Under the Curve): {roc_auc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
